<!--
 * @Descripttion: 
 * @version: 
 * @Author: cm.d
 * @Date: 2021-11-06 15:39:45
 * @LastEditors: cm.d
 * @LastEditTime: 2021-11-06 16:15:25
-->

# 作业帮 PB 级低成本日志检索服务【阅读随笔】

## 原文链接

原文链接：[作业帮 PB 级低成本日志检索服务](https://www.infoq.cn/article/xyDSrOGbg6tVDVEb261O)

## 阅读随笔

作业帮最近疯狂输出，而且还都比较硬。前几天在稀土大会的直播上，也有作业帮的服务治理相关的分享，今天在Infoq上又看到了作业帮的新货。撸一下，看看作业帮在日志上做了哪些事情。

### 需求场景

1. 写入要求搞，每秒千万级日志条数
2. 实时要求高：日志处理从采集到可以被检索的时间正常 1s 以内（高峰时期 3s）
3. 成本压力巨大，要求保存半年的日志且可以回溯查询（百 PB 规模）

### ElasticSearch 的不足

1. 写入性能：无法满足需求，瓶颈明显
2. 数据结构非常松散，磁盘空间浪费大。同时还有大量的索引、数据分片、缓存需要维护
3. 非结构化支持不好

### 日志检索系统的设计

#### 1.日志分块

不对原文建索引，只是对日志级别、类型、所属实例、时间进行分块。写入效率高，对日志格式无要求。然后通过支持grep查询。

#### 2.元数据索引

基于日志块的元信息建立索引，如图：  
![图](https://static001.infoq.cn/resource/image/16/06/16fd67096b1b93e91ed5b4eb7914c706.png)

#### 3.日志生命周期与数据沉降

![大致的结构](https://static001.infoq.cn/resource/image/75/16/75f67436650eedd2191c05ae2311d216.png)

本地存储负责提供实时和短期的日志查询(一天或几个小时)， 远程存储负责一定时期内的日志查询需求(一周或者几周)， 归档存储负责日志整个生命周期里的查询需求。归档存储的成本是本地存储的1/10  

![图](https://static001.infoq.cn/resource/image/a5/fa/a5605a4fba90fc5a1712d77d65a5c9fa.png)

需要读取的日志不在存储的话，需要去远程或者压缩存储拿，分钟级别

### 检索服务架构

+ GD-Search：查询调度器， 负责接受查询请求， 对查询命令做解析和优化， 并从 Chunk Index 中获取查询范围内日志块的地址， 最终生成分布式的查询计划
+ Local-Search：本地存储查询器， 负责处理 GD-Search 分配过来的本地日志块的查询请求。
+ Remote-Search：远程存储查询器， 负责处理 GD-Search 分配过来的远程日志块的查询请求。
+ Log-Manager：管理本地日志生命周期（压缩算法ZSTD）
+ Log-Ingester：日志摄取器模块， 负责从日志 kafka 订阅日志数据，然后将日志数据按时间维度和元数据维度拆分，写入到对应的日志块中。
+ Chunk Index：元信息索引存储，基于Redis

这里有一点，原文没有说明Redis的一致性问题  

![图](https://static001.infoq.cn/resource/image/e6/cf/e654a6bb062cbf193a470c655d9111cf.png)

整体数据流图，还是很清晰的

### 检索策略

抽象的日志查询场景：
1. 查看最新的服务日志
2. 查看某个请求的日志， 依据 logid 来查询
3. 查看某类日志， 像访问 mysql 的错误日志， 请求下游服务的日志等等

通过limit限制

### 性能一览

测试标准：使用 1KB 每条的日志进行测试， 总的日志块数量在 10000 左右， 本地存储使用 NVME SSD 硬盘， 远程存储使用 S3 协议标准存储
+ 写性能：单核可支持 2W 条/S 的写入速度， 1W 条/S 的写入速度约占用 1~2G 左右的内存，可分布式扩展，无上限。
+ 查询(全文检索)：
  + 基于本地存储的 1TB 日志数据查询速度可在 3S 以内完成
  + 基于远程存储的 1TB 日志数据查询耗时在 10S 以内完成

